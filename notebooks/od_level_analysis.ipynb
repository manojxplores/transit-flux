{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e36d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import holidays\n",
    "from datetime import timedelta\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f33e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 600,672\n",
      "Date range: 2017-10-01 00:00:00 to 2018-03-31 23:45:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "urbanbus_data = pd.read_csv('../urbanbus_data/SER_0b91_start_aggregated.csv')\n",
    "\n",
    "df = urbanbus_data.groupby([\"Ride_start_datetime\", \"Bus_Service_Number\", \"Direction\", \"Boarding_stop_stn\", \"Alighting_stop_stn\"], as_index=False)[\"Passenger_Count\"].sum()\n",
    "df['Ride_start_datetime'] = pd.to_datetime(df['Ride_start_datetime'], errors='coerce')\n",
    "df = df.sort_values('Ride_start_datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {df['Ride_start_datetime'].min()} to {df['Ride_start_datetime'].max()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b26f453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ride_start_datetime</th>\n",
       "      <th>Bus_Service_Number</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Boarding_stop_stn</th>\n",
       "      <th>Alighting_stop_stn</th>\n",
       "      <th>Passenger_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01 00:00:00</td>\n",
       "      <td>SER_0b91</td>\n",
       "      <td>Start</td>\n",
       "      <td>AAW_1</td>\n",
       "      <td>APN_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-01 00:00:00</td>\n",
       "      <td>SER_0b91</td>\n",
       "      <td>Start</td>\n",
       "      <td>AAW_1</td>\n",
       "      <td>CNA_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-01 00:15:00</td>\n",
       "      <td>SER_0b91</td>\n",
       "      <td>Start</td>\n",
       "      <td>APN_1</td>\n",
       "      <td>AHP_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-01 05:45:00</td>\n",
       "      <td>SER_0b91</td>\n",
       "      <td>Start</td>\n",
       "      <td>IH_2</td>\n",
       "      <td>EQI_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-01 05:45:00</td>\n",
       "      <td>SER_0b91</td>\n",
       "      <td>Start</td>\n",
       "      <td>IH_2</td>\n",
       "      <td>EHI_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ride_start_datetime Bus_Service_Number Direction Boarding_stop_stn  \\\n",
       "0 2017-10-01 00:00:00           SER_0b91     Start             AAW_1   \n",
       "1 2017-10-01 00:00:00           SER_0b91     Start             AAW_1   \n",
       "2 2017-10-01 00:15:00           SER_0b91     Start             APN_1   \n",
       "3 2017-10-01 05:45:00           SER_0b91     Start              IH_2   \n",
       "4 2017-10-01 05:45:00           SER_0b91     Start              IH_2   \n",
       "\n",
       "  Alighting_stop_stn  Passenger_Count  \n",
       "0              APN_1                1  \n",
       "1              CNA_1                1  \n",
       "2              AHP_1                1  \n",
       "3              EQI_1                4  \n",
       "4              EHI_1                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da08a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 18]\n"
     ]
    }
   ],
   "source": [
    "# Datetime features\n",
    "df['hour'] = df['Ride_start_datetime'].dt.hour\n",
    "df['minute'] = df['Ride_start_datetime'].dt.minute\n",
    "df['day'] = df['Ride_start_datetime'].dt.day\n",
    "df['dayofweek'] = df['Ride_start_datetime'].dt.dayofweek\n",
    "df['month'] = df['Ride_start_datetime'].dt.month\n",
    "df['year'] = df['Ride_start_datetime'].dt.year\n",
    "df['week_of_year'] = df['Ride_start_datetime'].dt.isocalendar().week\n",
    "\n",
    "# Cyclic encoding\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Peak hour flags\n",
    "peak_hours = df.groupby('hour')['Passenger_Count'].sum().nlargest(2).index.tolist()\n",
    "df['is_peak_hour'] = df['hour'].isin(peak_hours).astype(int)\n",
    "print(peak_hours)\n",
    "\n",
    "# Weekend and holiday flag\n",
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "china_holidays = holidays.country_holidays('CN')\n",
    "df['is_holiday'] = df['Ride_start_datetime'].dt.date.isin(china_holidays).astype(int)\n",
    "\n",
    "# Route identifier\n",
    "df['route'] = df['Boarding_stop_stn'] + '_to_' + df['Alighting_stop_stn']\n",
    "df = df.sort_values(['route', 'Ride_start_datetime']).reset_index(drop=True)\n",
    "\n",
    "# Lag Features\n",
    "for lag in [1, 2, 3, 4, 8, 12, 24]:\n",
    "    df[f'lag_{lag}'] = df.groupby('route')['Passenger_Count'].shift(lag)\n",
    "\n",
    "for window in [4, 8, 12, 24]:\n",
    "    df[f'rolling_mean_{window}'] = (\n",
    "        df.groupby('route')['Passenger_Count']\n",
    "        .shift(1)\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "    )\n",
    "    df[f'rolling_std_{window}'] = (\n",
    "        df.groupby('route')['Passenger_Count']\n",
    "        .shift(1)\n",
    "        .rolling(window=window)\n",
    "        .std()\n",
    "    )\n",
    "\n",
    "\n",
    "lag_roll_cols = [col for col in df.columns if col.startswith(('lag_', 'rolling_'))]\n",
    "df = df.dropna(subset=lag_roll_cols).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c93c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 497,989 records (2017-10-01 16:15:00 to 2018-03-04 23:30:00)\n",
      "Test Set: 89,785 records (2018-03-04 23:45:00 to 2018-03-31 23:45:00)\n",
      "Split: 84.7% train / 15.3% test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_date = df['Ride_start_datetime'].max()\n",
    "cutoff_date = max_date - timedelta(days=27)\n",
    "\n",
    "train_df = df[df['Ride_start_datetime'] < cutoff_date].copy()\n",
    "test_df = df[df['Ride_start_datetime'] >= cutoff_date].copy()\n",
    "\n",
    "print(f\"Training Set: {len(train_df):,} records ({train_df['Ride_start_datetime'].min()} to {train_df['Ride_start_datetime'].max()})\")\n",
    "print(f\"Test Set: {len(test_df):,} records ({test_df['Ride_start_datetime'].min()} to {test_df['Ride_start_datetime'].max()})\")\n",
    "print(f\"Split: {len(train_df)/len(df)*100:.1f}% train / {len(test_df)/len(df)*100:.1f}% test\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c29643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrices:\n",
      "  X_train: (497989, 35)\n",
      "  X_test: (89785, 35)\n",
      "  Total features: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['Boarding_stop_stn', 'Alighting_stop_stn']\n",
    "\n",
    "# All numerical features\n",
    "num_cols = [\n",
    "    'hour', 'minute', 'day', 'dayofweek', 'month', 'year', 'week_of_year',\n",
    "    'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', \n",
    "    'dow_sin', 'dow_cos', 'month_sin', 'month_cos',\n",
    "    'is_weekend', 'is_holiday', 'is_peak_hour']\n",
    "\n",
    "# Add lag and rolling features\n",
    "lag_roll_cols = [col for col in train_df.columns if col.startswith(('lag_', 'rolling_'))]\n",
    "num_cols.extend(lag_roll_cols)\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train = train_df[cat_cols + num_cols].copy()\n",
    "y_train = train_df['Passenger_Count'].copy()\n",
    "X_test = test_df[cat_cols + num_cols].copy()\n",
    "y_test = test_df['Passenger_Count'].copy()\n",
    "\n",
    "print(f\"Feature matrices:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  Total features: {len(cat_cols + num_cols)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f89c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.abs(y_true) + np.abs(y_pred)\n",
    "    mask = denom != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(2.0 * np.abs(y_true[mask] - y_pred[mask]) / denom[mask]) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred, set_name=\"Set\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f\"\\n{set_name} Performance:\")\n",
    "    print(f\"  MAE:   {mae:.4f}\")\n",
    "    print(f\"  RMSE:  {rmse:.4f}\")\n",
    "    print(f\"  R²:    {r2:.4f}\")\n",
    "    print(f\"  MAPE:  {mape:.2f}%\")\n",
    "    print(f\"  sMAPE: {smape:.2f}%\")\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE': mape, 'sMAPE': smape}\n",
    "\n",
    "def train_and_evaluate_model(model_name, model, X_train, y_train, X_test, y_test,\n",
    "                             cat_cols=None, preprocessor=True):\n",
    "    \n",
    "    print(f\"\\n{'='*20} Training {model_name} {'='*20}\\n\")\n",
    "    \n",
    "    if model_name.lower() == 'catboost':\n",
    "        all_features = list(X_train.columns)\n",
    "        cat_feature_indices = [all_features.index(c) for c in cat_cols] if cat_cols else []\n",
    "        train_pool = Pool(X_train, y_train, cat_features=cat_feature_indices)\n",
    "        test_pool = Pool(X_test, y_test, cat_features=cat_feature_indices)\n",
    "        model.fit(train_pool, eval_set=test_pool, use_best_model=False, verbose=100)\n",
    "        y_train_pred = model.predict(train_pool)\n",
    "        y_test_pred = model.predict(test_pool)\n",
    "    else:\n",
    "        if preprocessor:\n",
    "            pipe = Pipeline([\n",
    "                ('preprocessor', ColumnTransformer([\n",
    "                    ('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_cols),\n",
    "                    ('scaler', StandardScaler(), [c for c in X_train.columns if c not in cat_cols])\n",
    "                ], remainder='drop', verbose_feature_names_out=False)),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_train_pred = pipe.predict(X_train)\n",
    "            y_test_pred = pipe.predict(X_test)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\nTraining Set Metrics:\")\n",
    "    train_metrics = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "    \n",
    "    print(\"\\nTest Set Metrics:\")\n",
    "    test_metrics = evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "    \n",
    "    # Overfitting check\n",
    "    r2_gap = train_metrics['R2'] - test_metrics['R2']\n",
    "    print(f\"\\nOverfitting R² Gap: {r2_gap:.4f}\")\n",
    "    if r2_gap > 0.15:\n",
    "        print(\"⚠️ Significant overfitting\")\n",
    "    elif r2_gap > 0.05:\n",
    "        print(\"⚡ Slight overfitting\")\n",
    "    else:\n",
    "        print(\"✓ Good generalization\")\n",
    "    \n",
    "    return y_train_pred, y_test_pred, train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355c68b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training XGBoost ====================\n",
      "\n",
      "\n",
      "Training Set Metrics:\n",
      "\n",
      "Training Performance:\n",
      "  MAE:   0.6311\n",
      "  RMSE:  0.9507\n",
      "  R²:    0.4027\n",
      "  MAPE:  40.57%\n",
      "  sMAPE: 36.68%\n",
      "\n",
      "Test Set Metrics:\n",
      "\n",
      "Test Performance:\n",
      "  MAE:   0.6588\n",
      "  RMSE:  1.0473\n",
      "  R²:    0.2929\n",
      "  MAPE:  42.23%\n",
      "  sMAPE: 37.56%\n",
      "\n",
      "Overfitting R² Gap: 0.1098\n",
      "⚡ Slight overfitting\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=10, \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8, \n",
    "    objective='reg:squarederror', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "y_train_pred_xgb, y_test_pred_xgb, train_metrics_xgb, test_metrics_xgb = train_and_evaluate_model(\"XGBoost\", xgb_model, X_train, y_train, X_test, y_test, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8793c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training LightGBM ====================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1921\n",
      "[LightGBM] [Info] Number of data points in the train set: 497989, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score 1.560767\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Metrics:\n",
      "\n",
      "Training Performance:\n",
      "  MAE:   0.6483\n",
      "  RMSE:  1.0064\n",
      "  R²:    0.3306\n",
      "  MAPE:  41.38%\n",
      "  sMAPE: 37.12%\n",
      "\n",
      "Test Set Metrics:\n",
      "\n",
      "Test Performance:\n",
      "  MAE:   0.6540\n",
      "  RMSE:  1.0474\n",
      "  R²:    0.2928\n",
      "  MAPE:  41.73%\n",
      "  sMAPE: 37.17%\n",
      "\n",
      "Overfitting R² Gap: 0.0379\n",
      "✓ Good generalization\n"
     ]
    }
   ],
   "source": [
    "lgb_model = LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=40,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "y_train_pred_lgb, y_test_pred_lgb, train_metrics_lgb, test_metrics_lgb = train_and_evaluate_model(\"LightGBM\", lgb_model, X_train, y_train, X_test, y_test, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b01279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training CatBoost ====================\n",
      "\n",
      "0:\tlearn: 0.5603437\ttest: 0.5515743\tbest: 0.5515743 (0)\ttotal: 182ms\tremaining: 6m 4s\n",
      "100:\tlearn: 0.5405859\ttest: 0.5298065\tbest: 0.5298065 (100)\ttotal: 7.99s\tremaining: 2m 30s\n",
      "200:\tlearn: 0.5390099\ttest: 0.5283935\tbest: 0.5283933 (199)\ttotal: 14.5s\tremaining: 2m 10s\n",
      "300:\tlearn: 0.5365236\ttest: 0.5260820\tbest: 0.5260820 (300)\ttotal: 21s\tremaining: 1m 58s\n",
      "400:\tlearn: 0.5349953\ttest: 0.5248225\tbest: 0.5248225 (400)\ttotal: 27.3s\tremaining: 1m 48s\n",
      "500:\tlearn: 0.5341115\ttest: 0.5242609\tbest: 0.5242609 (500)\ttotal: 33.1s\tremaining: 1m 39s\n",
      "600:\tlearn: 0.5335405\ttest: 0.5237781\tbest: 0.5237781 (600)\ttotal: 39.1s\tremaining: 1m 31s\n",
      "700:\tlearn: 0.5332227\ttest: 0.5236044\tbest: 0.5236044 (700)\ttotal: 45s\tremaining: 1m 23s\n",
      "800:\tlearn: 0.5327494\ttest: 0.5233088\tbest: 0.5233088 (800)\ttotal: 51.1s\tremaining: 1m 16s\n",
      "900:\tlearn: 0.5321435\ttest: 0.5228892\tbest: 0.5228892 (900)\ttotal: 57.7s\tremaining: 1m 10s\n",
      "1000:\tlearn: 0.5316140\ttest: 0.5225768\tbest: 0.5225768 (1000)\ttotal: 1m 4s\tremaining: 1m 4s\n",
      "1100:\tlearn: 0.5306046\ttest: 0.5218909\tbest: 0.5218909 (1100)\ttotal: 1m 11s\tremaining: 58.5s\n",
      "1200:\tlearn: 0.5299460\ttest: 0.5214930\tbest: 0.5214930 (1200)\ttotal: 1m 18s\tremaining: 52.4s\n",
      "1300:\tlearn: 0.5293911\ttest: 0.5211786\tbest: 0.5211768 (1291)\ttotal: 1m 25s\tremaining: 46.2s\n",
      "1400:\tlearn: 0.5290110\ttest: 0.5209090\tbest: 0.5209090 (1400)\ttotal: 1m 33s\tremaining: 39.9s\n",
      "1500:\tlearn: 0.5286518\ttest: 0.5207908\tbest: 0.5207851 (1467)\ttotal: 1m 40s\tremaining: 33.4s\n",
      "1600:\tlearn: 0.5283338\ttest: 0.5206591\tbest: 0.5206591 (1600)\ttotal: 1m 46s\tremaining: 26.6s\n",
      "1700:\tlearn: 0.5280502\ttest: 0.5205193\tbest: 0.5205180 (1698)\ttotal: 1m 52s\tremaining: 19.9s\n",
      "1800:\tlearn: 0.5276159\ttest: 0.5202879\tbest: 0.5202877 (1799)\ttotal: 1m 59s\tremaining: 13.2s\n",
      "1900:\tlearn: 0.5273310\ttest: 0.5201946\tbest: 0.5201946 (1900)\ttotal: 2m 5s\tremaining: 6.52s\n",
      "1999:\tlearn: 0.5271387\ttest: 0.5201322\tbest: 0.5201235 (1996)\ttotal: 2m 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5201234752\n",
      "bestIteration = 1996\n",
      "\n",
      "\n",
      "Training Set Metrics:\n",
      "\n",
      "Training Performance:\n",
      "  MAE:   0.5271\n",
      "  RMSE:  1.1803\n",
      "  R²:    0.0792\n",
      "  MAPE:  20.38%\n",
      "  sMAPE: 25.40%\n",
      "\n",
      "Test Set Metrics:\n",
      "\n",
      "Test Performance:\n",
      "  MAE:   0.5201\n",
      "  RMSE:  1.1789\n",
      "  R²:    0.1040\n",
      "  MAPE:  20.06%\n",
      "  sMAPE: 25.00%\n",
      "\n",
      "Overfitting R² Gap: -0.0248\n",
      "✓ Good generalization\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor(\n",
    "    iterations=2000, \n",
    "    learning_rate=0.05, \n",
    "    depth=8, \n",
    "    l2_leaf_reg=3,\n",
    "    loss_function='MAE', \n",
    "    eval_metric='MAE', \n",
    "    random_seed=42,\n",
    "    task_type='CPU', \n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "y_train_pred_cat, y_test_pred_cat, train_metrics_cat, test_metrics_cat = train_and_evaluate_model(\"CatBoost\", cat_model, X_train, y_train, X_test, y_test, cat_cols=cat_cols, preprocessor=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
